{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from synthcity.metrics.eval import Metrics\n",
    "import pandas as pd\n",
    "def synthcity_evaluate(real_path,\n",
    "                       syn_path,\n",
    "                       result_name=None,\n",
    "                       real_size = None,\n",
    "                       syn_size = None):\n",
    "    real_data = pd.read_csv(real_path)\n",
    "    syn_data = pd.read_csv(syn_path)\n",
    "    \n",
    "    if real_size and real_size < len(real_data):\n",
    "        real_data = real_data.sample(n=real_size, random_state=42)  # Adjust random_state as desired for reproducibility\n",
    "\n",
    "    if syn_size and syn_size < len(syn_data):\n",
    "        syn_data = syn_data.sample(n=syn_size, random_state=42)\n",
    "    \n",
    "    metrics = {\n",
    "        'sanity': ['data_mismatch', 'nearest_syn_neighbor_distance', 'close_values_probability'],\n",
    "        'stats': ['jensenshannon_dist', 'feature_corr', 'ks_test', 'max_mean_discrepancy', 'prdc', 'alpha_precision'],\n",
    "        'performance': ['linear_model', 'mlp', 'xgb'],\n",
    "        # 'detection': ['detection_xgb', 'detection_mlp', 'detection_linear'],\n",
    "        # 'privacy': ['delta-presence', 'k-anonymization', 'k-map', 'distinct l-diversity', 'identifiability_score']\n",
    "    }\n",
    "    \n",
    "    synthcity_result = Metrics.evaluate(real_data, syn_data, metrics=metrics)\n",
    "    if result_name:\n",
    "        synthcity_result.to_csv(result_name)\n",
    "    return synthcity_result\n",
    "    \n",
    "    \n",
    "def compare(real_file_name, no_water_mark_file_name, with_water_mark_file_name, size=200, round_to=None):\n",
    "    samples_dir = \"/Users/minhkau/Documents/TUDelft/Year 3/RP/Code/tabular-gpt/samples/\"\n",
    "    real_path = samples_dir + real_file_name\n",
    "    synth_no_watermark_path = samples_dir + no_water_mark_file_name\n",
    "    synth_with_watermark_path = samples_dir + with_water_mark_file_name\n",
    "    \n",
    "    \n",
    "    real_df = synthcity_evaluate(real_path, real_path, real_size=size, syn_size=size)[[\"min\"]]\n",
    "    no_water_mark_df = synthcity_evaluate(real_path, synth_no_watermark_path, real_size=size, syn_size=size)[[\"min\"]]\n",
    "    with_watermark_df = synthcity_evaluate(real_path, synth_with_watermark_path, real_size=size, syn_size=size)[[\"min\", \"direction\"]]\n",
    "    merge_result = real_df.join(no_water_mark_df, lsuffix='_real', rsuffix='_no_watermark')\n",
    "    merge_result_final = merge_result.join(with_watermark_df)\n",
    "    \n",
    "    merge_result_final.columns = [\"Real Data\", \"No-Watermark\", \"With-Watermark\", \"Direction\"]\n",
    "    if round_to:\n",
    "        merge_result_final = merge_result_final.round(round_to)\n",
    "    return merge_result_final"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:21:12.724824Z",
     "start_time": "2024-05-17T09:21:12.719317Z"
    }
   },
   "id": "bb7c4edff18fb25b",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1.0716398609228073"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Make 2 functions:\n",
    "    - [x] average synthetic data quality, with watermarks and without watermark\n",
    "    - [x] average z-score, takes ~50 random samples of size 200 tokens\n",
    "    \n",
    "\"\"\"\n",
    "from watermarking.great_watermark import GreatWatermarkLogitProcessor, GreatWatermarkDetector\n",
    "import transformers\n",
    "\n",
    "def average_data_quality(real_file_name, no_water_mark_file_name, with_water_mark_file_name, size=200):\n",
    "    \"\"\"\n",
    "    Compute the average quality of synthetic data, with watermarks and without watermarks\n",
    "    The scores are divided into 3 groups: resemblance, ML utility and discriminatory \n",
    "    Args:\n",
    "        real_file_name: \n",
    "        no_water_mark_file_name: \n",
    "        with_water_mark_file_name: \n",
    "        size: default to 200 tokens\n",
    "    \"\"\"\n",
    "\n",
    "    scores = compare(\n",
    "        real_file_name = real_file_name,\n",
    "        no_water_mark_file_name = no_water_mark_file_name,\n",
    "        with_water_mark_file_name = with_water_mark_file_name,\n",
    "        size = size\n",
    "    )\n",
    "    \n",
    "    for col in ['Real Data', 'No-Watermark', 'With-Watermark']:\n",
    "        scores[col] = scores.apply(lambda row: 1 - row[col] if row['Direction'] == 'minimize' else row[col], axis=1)\n",
    "    \n",
    "    scores =  scores.drop('Direction', axis=1)\n",
    "    scores = scores.astype(float)\n",
    "\n",
    "    # Resemblance\n",
    "    resemblance_metrics = ['stats.jensenshannon_dist.marginal',\n",
    "                           'stats.ks_test.marginal',\n",
    "                           'stats.max_mean_discrepancy.joint',\n",
    "               'stats.prdc.precision', 'stats.prdc.recall', 'stats.prdc.density', 'stats.prdc.coverage',\n",
    "               'stats.alpha_precision.delta_precision_alpha_OC', 'stats.alpha_precision.delta_coverage_beta_OC',\n",
    "               'stats.alpha_precision.authenticity_OC', 'stats.alpha_precision.delta_precision_alpha_naive',\n",
    "               'stats.alpha_precision.delta_coverage_beta_naive', 'stats.alpha_precision.authenticity_naive'],\n",
    "    resemblance_df = scores.loc[resemblance_metrics]  \n",
    "    resemblance_scores = resemblance_df[['No-Watermark', 'With-Watermark']].mean()\n",
    "    \n",
    "    # ML utility metrics\n",
    "    linear_performance = scores.loc['performance.linear_model.syn_id'] / scores.loc['performance.linear_model.gt']\n",
    "    mlp_performance = scores.loc['performance.mlp.syn_id'] / scores.loc['performance.mlp.gt']\n",
    "    xgb_performance = scores.loc['performance.xgb.syn_id'] / scores.loc['performance.xgb.gt']\n",
    "    ml_performance_scores = (linear_performance + mlp_performance + xgb_performance).drop(\"Real Data\") / 3\n",
    "\n",
    "    final_scores = {\n",
    "        \"resemblance\": resemblance_scores,\n",
    "        \"ml_performance\": ml_performance_scores,\n",
    "        \"avg_final_score\": (resemblance_scores + ml_performance_scores) / 2\n",
    "    }\n",
    "    return final_scores\n",
    "    \n",
    "def average_zscore(sample_name, gamma, delta, num_tokens, num_samples = 50):\n",
    "    \"\"\"\n",
    "    Compute the average z_score over a number of random samples from the synthesized data\n",
    "    \"\"\"\n",
    "    samples_dir = \"/Users/minhkau/Documents/TUDelft/Year 3/RP/Code/tabular-gpt/samples/\"\n",
    "    sample_df = pd.read_csv(samples_dir + sample_name)\n",
    "    \n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained('distilgpt2', add_prefix_space=True)\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    great_watermark_processor = GreatWatermarkLogitProcessor(tokenizer=tokenizer,\n",
    "                                                             device=\"cpu\",\n",
    "                                                             vocab=list(tokenizer.get_vocab().values()),\n",
    "                                                             gamma=gamma,\n",
    "                                                             delta=delta)\n",
    "    great_watermark_detector = GreatWatermarkDetector(great_watermark_processor)\n",
    "    \n",
    "    z_scores = []\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        z_scores.append(great_watermark_detector.detect(\n",
    "            sample_df,\n",
    "            total_tokens_limit=num_tokens,\n",
    "            random_state=i\n",
    "        )['z_score'])\n",
    "    return sum(z_scores) / len(z_scores)\n",
    "              "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T10:19:50.429521Z",
     "start_time": "2024-05-17T10:19:49.371308Z"
    }
   },
   "id": "994a602c00870309",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "compare(\n",
    "    \"abalone.csv\",\n",
    "    \"abalone_v_baseline_1000_non-watermark.csv\",\n",
    "    \"abalone_v_baseline_1000_with-watermark_gamma-0.25_delta-2.0.csv\",\n",
    "    1000\n",
    ").to_csv(\"lmao.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T09:31:01.621336Z",
     "start_time": "2024-05-17T09:31:01.451754Z"
    }
   },
   "id": "554be5fb5569d987",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Real Data  No-Watermark  \\\nsanity.data_mismatch.score                              0.00          0.00   \nsanity.nearest_syn_neighbor_distance.mean               0.00          0.01   \nsanity.close_values_probability.score                   1.00          0.98   \nstats.jensenshannon_dist.marginal                       0.00          0.01   \nstats.ks_test.marginal                                  1.00          0.90   \nstats.max_mean_discrepancy.joint                        0.00          0.00   \nstats.prdc.precision                                    1.00          0.99   \nstats.prdc.recall                                       1.00          0.94   \nstats.prdc.density                                      1.00          0.95   \nstats.prdc.coverage                                     1.00          0.85   \nstats.alpha_precision.delta_precision_alpha_OC          1.00          0.93   \nstats.alpha_precision.delta_coverage_beta_OC            1.00          0.36   \nstats.alpha_precision.authenticity_OC                   0.00          0.57   \nstats.alpha_precision.delta_precision_alpha_naive       1.00          0.85   \nstats.alpha_precision.delta_coverage_beta_naive         1.00          0.28   \nstats.alpha_precision.authenticity_naive                0.00          0.64   \nperformance.linear_model.gt                             0.66          0.66   \nperformance.linear_model.syn_id                         0.68          0.38   \nperformance.linear_model.syn_ood                        0.61          0.25   \nperformance.mlp.gt                                     -5.57         -5.57   \nperformance.mlp.syn_id                                 -1.27         -1.74   \nperformance.mlp.syn_ood                                -1.89         -2.77   \nperformance.xgb.gt                                      0.70          0.70   \nperformance.xgb.syn_id                                  1.00          0.03   \nperformance.xgb.syn_ood                                 1.00         -0.04   \n\n                                                   With-Watermark Direction  \nsanity.data_mismatch.score                                   0.00  minimize  \nsanity.nearest_syn_neighbor_distance.mean                    0.01  minimize  \nsanity.close_values_probability.score                        0.98  maximize  \nstats.jensenshannon_dist.marginal                            0.02  minimize  \nstats.ks_test.marginal                                       0.75  maximize  \nstats.max_mean_discrepancy.joint                             0.00  minimize  \nstats.prdc.precision                                         1.00  maximize  \nstats.prdc.recall                                            0.96  maximize  \nstats.prdc.density                                           0.96  maximize  \nstats.prdc.coverage                                          0.62  maximize  \nstats.alpha_precision.delta_precision_alpha_OC               0.93  maximize  \nstats.alpha_precision.delta_coverage_beta_OC                 0.26  maximize  \nstats.alpha_precision.authenticity_OC                        0.62  maximize  \nstats.alpha_precision.delta_precision_alpha_naive            0.93  maximize  \nstats.alpha_precision.delta_coverage_beta_naive              0.19  maximize  \nstats.alpha_precision.authenticity_naive                     0.74  maximize  \nperformance.linear_model.gt                                  0.66  maximize  \nperformance.linear_model.syn_id                              0.40  maximize  \nperformance.linear_model.syn_ood                             0.35  maximize  \nperformance.mlp.gt                                          -5.57  maximize  \nperformance.mlp.syn_id                                      -2.22  maximize  \nperformance.mlp.syn_ood                                     -3.44  maximize  \nperformance.xgb.gt                                           0.70  maximize  \nperformance.xgb.syn_id                                       0.11  maximize  \nperformance.xgb.syn_ood                                      0.15  maximize  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Real Data</th>\n      <th>No-Watermark</th>\n      <th>With-Watermark</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sanity.data_mismatch.score</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>sanity.nearest_syn_neighbor_distance.mean</th>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>sanity.close_values_probability.score</th>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.jensenshannon_dist.marginal</th>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>stats.ks_test.marginal</th>\n      <td>1.00</td>\n      <td>0.90</td>\n      <td>0.75</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.max_mean_discrepancy.joint</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.precision</th>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.recall</th>\n      <td>1.00</td>\n      <td>0.94</td>\n      <td>0.96</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.density</th>\n      <td>1.00</td>\n      <td>0.95</td>\n      <td>0.96</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.coverage</th>\n      <td>1.00</td>\n      <td>0.85</td>\n      <td>0.62</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_precision_alpha_OC</th>\n      <td>1.00</td>\n      <td>0.93</td>\n      <td>0.93</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_coverage_beta_OC</th>\n      <td>1.00</td>\n      <td>0.36</td>\n      <td>0.26</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.authenticity_OC</th>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.62</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_precision_alpha_naive</th>\n      <td>1.00</td>\n      <td>0.85</td>\n      <td>0.93</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_coverage_beta_naive</th>\n      <td>1.00</td>\n      <td>0.28</td>\n      <td>0.19</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.authenticity_naive</th>\n      <td>0.00</td>\n      <td>0.64</td>\n      <td>0.74</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.gt</th>\n      <td>0.66</td>\n      <td>0.66</td>\n      <td>0.66</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.syn_id</th>\n      <td>0.68</td>\n      <td>0.38</td>\n      <td>0.40</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.syn_ood</th>\n      <td>0.61</td>\n      <td>0.25</td>\n      <td>0.35</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.gt</th>\n      <td>-5.57</td>\n      <td>-5.57</td>\n      <td>-5.57</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.syn_id</th>\n      <td>-1.27</td>\n      <td>-1.74</td>\n      <td>-2.22</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.syn_ood</th>\n      <td>-1.89</td>\n      <td>-2.77</td>\n      <td>-3.44</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.gt</th>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>0.70</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.syn_id</th>\n      <td>1.00</td>\n      <td>0.03</td>\n      <td>0.11</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.syn_ood</th>\n      <td>1.00</td>\n      <td>-0.04</td>\n      <td>0.15</td>\n      <td>maximize</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very low since there's no target column\n",
    "compare(\n",
    "    \"california.csv\",\n",
    "    \"california_1000_non-watermark.csv\",\n",
    "    \"california_1000_with-watermark_gamma-0.25_delta-2.0.csv\",\n",
    "    1000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T12:05:01.364799Z",
     "start_time": "2024-05-14T12:05:00.115576Z"
    }
   },
   "id": "1abf6e7709e45e1b",
   "execution_count": 178
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Real Data  No-Watermark  \\\nsanity.data_mismatch.score                              0.00          0.50   \nsanity.nearest_syn_neighbor_distance.mean               0.00          0.05   \nsanity.close_values_probability.score                   1.00          0.98   \nstats.jensenshannon_dist.marginal                       0.00          0.02   \nstats.ks_test.marginal                                  1.00          0.83   \nstats.max_mean_discrepancy.joint                        0.00          0.00   \nstats.prdc.precision                                    1.00          0.98   \nstats.prdc.recall                                       1.00          0.90   \nstats.prdc.density                                      1.00          1.11   \nstats.prdc.coverage                                     1.00          0.83   \nstats.alpha_precision.delta_precision_alpha_OC          1.00          0.99   \nstats.alpha_precision.delta_coverage_beta_OC            1.00          0.49   \nstats.alpha_precision.authenticity_OC                   0.00          0.52   \nstats.alpha_precision.delta_precision_alpha_naive       1.00          0.85   \nstats.alpha_precision.delta_coverage_beta_naive         1.00          0.42   \nstats.alpha_precision.authenticity_naive                0.00          0.55   \nperformance.linear_model.gt                             0.81          0.81   \nperformance.linear_model.syn_id                         0.84          0.79   \nperformance.linear_model.syn_ood                        0.85          0.79   \nperformance.mlp.gt                                      0.50          0.50   \nperformance.mlp.syn_id                                  0.46          0.44   \nperformance.mlp.syn_ood                                 0.50          0.46   \nperformance.xgb.gt                                      0.78          0.78   \nperformance.xgb.syn_id                                  1.00          0.60   \nperformance.xgb.syn_ood                                 1.00          0.57   \n\n                                                   With-Watermark Direction  \nsanity.data_mismatch.score                                   0.50  minimize  \nsanity.nearest_syn_neighbor_distance.mean                    0.17  minimize  \nsanity.close_values_probability.score                        0.71  maximize  \nstats.jensenshannon_dist.marginal                            0.02  minimize  \nstats.ks_test.marginal                                       0.79  maximize  \nstats.max_mean_discrepancy.joint                             0.00  minimize  \nstats.prdc.precision                                         0.98  maximize  \nstats.prdc.recall                                            0.86  maximize  \nstats.prdc.density                                           1.07  maximize  \nstats.prdc.coverage                                          0.85  maximize  \nstats.alpha_precision.delta_precision_alpha_OC               0.90  maximize  \nstats.alpha_precision.delta_coverage_beta_OC                 0.44  maximize  \nstats.alpha_precision.authenticity_OC                        0.50  maximize  \nstats.alpha_precision.delta_precision_alpha_naive            0.77  maximize  \nstats.alpha_precision.delta_coverage_beta_naive              0.39  maximize  \nstats.alpha_precision.authenticity_naive                     0.61  maximize  \nperformance.linear_model.gt                                  0.81  maximize  \nperformance.linear_model.syn_id                              0.81  maximize  \nperformance.linear_model.syn_ood                             0.81  maximize  \nperformance.mlp.gt                                           0.50  maximize  \nperformance.mlp.syn_id                                       0.48  maximize  \nperformance.mlp.syn_ood                                      0.50  maximize  \nperformance.xgb.gt                                           0.78  maximize  \nperformance.xgb.syn_id                                       0.62  maximize  \nperformance.xgb.syn_ood                                      0.68  maximize  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Real Data</th>\n      <th>No-Watermark</th>\n      <th>With-Watermark</th>\n      <th>Direction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>sanity.data_mismatch.score</th>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>sanity.nearest_syn_neighbor_distance.mean</th>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.17</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>sanity.close_values_probability.score</th>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.71</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.jensenshannon_dist.marginal</th>\n      <td>0.00</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>stats.ks_test.marginal</th>\n      <td>1.00</td>\n      <td>0.83</td>\n      <td>0.79</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.max_mean_discrepancy.joint</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>minimize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.precision</th>\n      <td>1.00</td>\n      <td>0.98</td>\n      <td>0.98</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.recall</th>\n      <td>1.00</td>\n      <td>0.90</td>\n      <td>0.86</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.density</th>\n      <td>1.00</td>\n      <td>1.11</td>\n      <td>1.07</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.prdc.coverage</th>\n      <td>1.00</td>\n      <td>0.83</td>\n      <td>0.85</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_precision_alpha_OC</th>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.90</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_coverage_beta_OC</th>\n      <td>1.00</td>\n      <td>0.49</td>\n      <td>0.44</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.authenticity_OC</th>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.50</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_precision_alpha_naive</th>\n      <td>1.00</td>\n      <td>0.85</td>\n      <td>0.77</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.delta_coverage_beta_naive</th>\n      <td>1.00</td>\n      <td>0.42</td>\n      <td>0.39</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>stats.alpha_precision.authenticity_naive</th>\n      <td>0.00</td>\n      <td>0.55</td>\n      <td>0.61</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.gt</th>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.syn_id</th>\n      <td>0.84</td>\n      <td>0.79</td>\n      <td>0.81</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.linear_model.syn_ood</th>\n      <td>0.85</td>\n      <td>0.79</td>\n      <td>0.81</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.gt</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.syn_id</th>\n      <td>0.46</td>\n      <td>0.44</td>\n      <td>0.48</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.mlp.syn_ood</th>\n      <td>0.50</td>\n      <td>0.46</td>\n      <td>0.50</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.gt</th>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.syn_id</th>\n      <td>1.00</td>\n      <td>0.60</td>\n      <td>0.62</td>\n      <td>maximize</td>\n    </tr>\n    <tr>\n      <th>performance.xgb.syn_ood</th>\n      <td>1.00</td>\n      <td>0.57</td>\n      <td>0.68</td>\n      <td>maximize</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very low since there's no target column\n",
    "compare(\n",
    "    \"diabetes.csv\",\n",
    "    \"diabetes_v_baseline_1000_non-watermark.csv\",\n",
    "    \"diabetes_v_baseline_1000_with-watermark_gamma-0.25_delta-2.0.csv\",\n",
    "    1000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T17:55:01.658546Z",
     "start_time": "2024-05-14T17:55:01.535827Z"
    }
   },
   "id": "f8578afb36db82a1",
   "execution_count": 182
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
