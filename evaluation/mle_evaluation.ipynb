{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "def get_filenames_from_model(model_name, common_size, gamma, delta, other_schemes=None):\n",
    "    # Define the search pattern, allowing any string for sample size part\n",
    "    search_pattern_non_watermark = f\"{model_name}_*_non-watermark.csv\"\n",
    "    search_pattern_watermark = f\"{model_name}_*_with-watermark_gamma-{gamma}_delta-{delta}.csv\"\n",
    "\n",
    "    # Use glob to get all files matching the search\n",
    "    directory = \"/Users/minhkau/Documents/TUDelft/Year 3/RP/Code/tabular-gpt/samples\"\n",
    "    files_non_watermark = glob.glob(search_pattern_non_watermark, root_dir=directory)\n",
    "    files_watermark = glob.glob(search_pattern_watermark, root_dir=directory)\n",
    "\n",
    "    # Regular expressions to extract sample size from filenames\n",
    "    regex_pattern_non_watermark = re.compile(rf\"{model_name}_(\\d+)_non-watermark.csv\")\n",
    "    regex_pattern_watermark = re.compile(rf\"{model_name}_(\\d+)_with-watermark_gamma-{gamma}_delta-{delta}.csv\")\n",
    "\n",
    "    largest_sample_size_non_watermark = -1\n",
    "    largest_sample_size_with_watermark = -1\n",
    "    largest_file_non_watermark = None\n",
    "    largest_file_with_watermark = None\n",
    "    # Iterate over the matching files and extract sample size\n",
    "    for file in files_non_watermark:\n",
    "        match = regex_pattern_non_watermark.match(os.path.basename(file))\n",
    "        if match:\n",
    "            sample_size = int(match.group(1))\n",
    "            if sample_size == common_size:\n",
    "                largest_file_non_watermark = file\n",
    "                break\n",
    "            if sample_size > largest_sample_size_non_watermark:\n",
    "                largest_sample_size_non_watermark = sample_size\n",
    "                largest_file_non_watermark = file\n",
    "\n",
    "    for file in files_watermark:\n",
    "        match = regex_pattern_watermark.match(os.path.basename(file))\n",
    "        if match:\n",
    "            sample_size = int(match.group(1))\n",
    "            if sample_size == common_size:\n",
    "                largest_file_with_watermark = file\n",
    "                break\n",
    "            if sample_size > largest_sample_size_with_watermark:\n",
    "                largest_sample_size_with_watermark = sample_size\n",
    "                largest_file_with_watermark = file\n",
    "                \n",
    "    if other_schemes:\n",
    "        other_schemes_file_names = []\n",
    "        for scheme_name in other_schemes:\n",
    "            search_pattern_scheme = f\"{model_name}_*_with-watermark_{scheme_name}.csv\"\n",
    "            regex_pattern_scheme = re.compile(rf\"{model_name}_(\\d+)_with-watermark_{scheme_name}.csv\")\n",
    "            files_scheme = glob.glob(search_pattern_scheme, root_dir=directory)\n",
    "            largest_sample_size_scheme = -1\n",
    "            largest_file_sheme = None\n",
    "            for file in files_scheme:\n",
    "                match = regex_pattern_scheme.match(os.path.basename(file))\n",
    "                if match:\n",
    "                    sample_size = int(match.group(1))\n",
    "                    if sample_size == common_size:\n",
    "                        largest_file_sheme = file\n",
    "                        break\n",
    "                    if sample_size > largest_sample_size_scheme:\n",
    "                        largest_sample_size_scheme = sample_size\n",
    "                        largest_file_sheme = file\n",
    "            other_schemes_file_names.append(largest_file_sheme)\n",
    "        return f\"{model_name}.csv\", largest_file_non_watermark, largest_file_with_watermark, other_schemes_file_names\n",
    "            \n",
    "    return f\"{model_name}.csv\", largest_file_non_watermark, largest_file_with_watermark\n",
    "\n",
    "def get_tables_by_model_name(model_name, common_size, gamma, delta, other_schemes):\n",
    "    real_file_name, no_water_mark_file_name, with_water_mark_file_name, other_schemes_file_names = get_filenames_from_model(model_name, common_size=common_size, gamma=gamma, delta=delta,other_schemes=other_schemes)\n",
    "            \n",
    "    samples_dir = \"/Users/minhkau/Documents/TUDelft/Year 3/RP/Code/tabular-gpt/samples/\"\n",
    "    real_path = samples_dir + real_file_name\n",
    "    synth_no_watermark_path = samples_dir + no_water_mark_file_name\n",
    "    synth_with_watermark_path = samples_dir + with_water_mark_file_name\n",
    "    exp_path = samples_dir + other_schemes_file_names[0]\n",
    "    \n",
    "    real_table = pd.read_csv(real_path)\n",
    "    non_watermark_table = pd.read_csv(synth_no_watermark_path)\n",
    "    watermark_table = pd.read_csv(synth_with_watermark_path)\n",
    "    exp_table = pd.read_csv(exp_path)\n",
    "    \n",
    "    return real_table, non_watermark_table, watermark_table, exp_table\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T13:13:48.062898Z",
     "start_time": "2024-06-09T13:13:48.059087Z"
    }
   },
   "id": "c76c125bfec8f652",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def preprocess_data(train, test, target, label_encoder = None):\n",
    "    X_train = train.drop(target, axis=1)\n",
    "    y_train = train[target]   \n",
    "    \n",
    "    X_test = test.drop(target, axis=1)\n",
    "    y_test = test[target]\n",
    "    \n",
    "    if label_encoder:\n",
    "        y_train = label_encoder.fit_transform(y_train)\n",
    "        y_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "    \n",
    "    numeric_features = X_train.select_dtypes(include=['int', 'float']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, preprocessor\n",
    "    \n",
    "# classifiers are used for adult and diabetes\n",
    "def logistic_classifier(train, test, target):\n",
    "    X_train, y_train, X_test, y_test, preprocessor = preprocess_data(train, test, target, label_encoder=LabelEncoder())\n",
    "    \n",
    "    # Create a pipeline with preprocessing and the classifier\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', LogisticRegression())])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    predictions_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test, predictions_proba)\n",
    "    \n",
    "    return {'f1': f1, 'auc': auc}\n",
    "\n",
    "def linear_classifier(train, test, target):\n",
    "    X_train, y_train, X_test, y_test, preprocessor = preprocess_data(train, test, target, label_encoder=LabelEncoder())\n",
    "\n",
    "    # Create a pipeline with preprocessing and the classifier\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', LinearRegression())])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities (continuous values) and threshold them to get binary predictions\n",
    "    predictions_prob = pipeline.predict(X_test)\n",
    "    threshold = 0.5\n",
    "    predictions = (predictions_prob >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions_prob)    \n",
    "    return {'f1': f1, 'auc': auc}\n",
    "\n",
    "def decision_tree_classifier(train, test, target):\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Preprocess the data\n",
    "    X_train, y_train, X_test, y_test, preprocessor = preprocess_data(train, test, target, label_encoder)\n",
    "    \n",
    "    # Create a pipeline with preprocessing and the classifier\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    # Predict probabilities for the positive class\n",
    "    predictions_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_test, predictions_prob)\n",
    "    \n",
    "    return {'f1': f1, 'auc': auc}\n",
    "\n",
    "# regression are used for california and abalone\n",
    "def linear_regresser(train, test, target):\n",
    "\n",
    "    X_train, y_train, X_test, y_test, preprocessor = preprocess_data(train, test, target)\n",
    "\n",
    "    # Create a pipeline with preprocessing and the classifier\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', LinearRegression())])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    return {'mae': mae, 'mse': mse, 'r2':r2}\n",
    "\n",
    "def random_forest_regressor(train, test, target):\n",
    "    X_train, y_train, X_test, y_test, preprocessor = preprocess_data(train, test, target)\n",
    "\n",
    "    # Create a pipeline with preprocessing and the regressor\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    return {'mae': mae, 'mse': mse, 'r2': r2}\n",
    "\n",
    "def mle_efficacy(models_meta_data, gamma_delta_pairs, common_size=1000, test_size=250, trial_num=5):\n",
    "    final_results = []\n",
    "    for meta in models_meta_data:\n",
    "        model_name = meta['model_name']\n",
    "        target = meta['target']\n",
    "        task_name = meta['task_name'] # either regression or classification\n",
    "        \n",
    "        for (gamma, delta) in gamma_delta_pairs:\n",
    "            real_table, non_watermark_table, watermark_table, exp_table = get_tables_by_model_name(model_name, common_size, gamma, delta, [\"exp\"])\n",
    "            \n",
    "            result = {\n",
    "                'linear_classification': [],\n",
    "                'logistic_classification': [],\n",
    "                'decision_tree_classification': [],\n",
    "                'linear_regression': [],\n",
    "                # 'decision_tree_regression': []\n",
    "                'random_forest_regression':[]\n",
    "            }\n",
    "            \n",
    "            \n",
    "            for i in range(trial_num):\n",
    "                test_real = real_table.sample(test_size, random_state=i)\n",
    "                real_table_dropped = real_table.drop(test_real.index, inplace=False)\n",
    "                \n",
    "                train_real = real_table_dropped.sample(common_size, random_state=i) if real_table.shape[0] > common_size else real_table_dropped\n",
    "                train_synth_no_W = non_watermark_table.copy()\n",
    "                train_synth_W = watermark_table.copy()\n",
    "                train_exp = exp_table.copy()\n",
    "                                \n",
    "                if task_name == 'classification':\n",
    "                    tasks = zip(['linear_classification', 'logistic_classification', 'decision_tree_classification'], [linear_classifier, logistic_classifier, decision_tree_classifier])\n",
    "                else:\n",
    "                    tasks = zip(['linear_regression', 'random_forest_regression'], [linear_regresser, random_forest_regressor])\n",
    "                    \n",
    "                for name, runner in tasks:\n",
    "                    result[name].append({\n",
    "                        'real': runner(train_real, test_real, target),\n",
    "                        'non_watermark': runner(train_synth_no_W, test_real, target),\n",
    "                        'watermark': runner(train_synth_W, test_real, target),\n",
    "                        'exp': runner(train_exp, test_real, target)\n",
    "                    })\n",
    "            \n",
    "            final_results.append({\n",
    "                'model_name': model_name,\n",
    "                'gamma':gamma,\n",
    "                'delta':delta,\n",
    "                'result':result,\n",
    "                'tasks': ['linear_classification', 'logistic_classification', 'decision_tree_classification'] if task_name == 'classification' else ['linear_regression', 'random_forest_regression']\n",
    "            })\n",
    "    return final_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T18:39:34.936382Z",
     "start_time": "2024-06-09T18:39:34.933454Z"
    }
   },
   "id": "8f2cad3c1a415bde",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m models_metadata \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# {'model_name': 'adult', 'target': 'class', 'task_name': 'classification'},\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# {'model_name': 'california', 'target': 'MedHouseVal', 'task_name': 'regression'},\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mabalone\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRings\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mregression\u001B[39m\u001B[38;5;124m'\u001B[39m},\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# {'model_name': 'diabetes', 'target': 'Outcome', 'task_name': 'classification'},\u001B[39;00m\n\u001B[1;32m      6\u001B[0m ]\n\u001B[1;32m      8\u001B[0m gamma_delta_pairs \u001B[38;5;241m=\u001B[39m [(\u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m5.0\u001B[39m), (\u001B[38;5;241m0.25\u001B[39m, \u001B[38;5;241m2.0\u001B[39m), (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m1.0\u001B[39m), (\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m2.0\u001B[39m)]\n\u001B[0;32m---> 10\u001B[0m mle_scores \u001B[38;5;241m=\u001B[39m \u001B[43mmle_efficacy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodels_metadata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma_delta_pairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n",
      "Cell \u001B[0;32mIn[15], line 176\u001B[0m, in \u001B[0;36mmle_efficacy\u001B[0;34m(models_meta_data, gamma_delta_pairs, common_size, test_size, trial_num)\u001B[0m\n\u001B[1;32m    173\u001B[0m task_name \u001B[38;5;241m=\u001B[39m meta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;66;03m# either regression or classification\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (gamma, delta) \u001B[38;5;129;01min\u001B[39;00m gamma_delta_pairs:\n\u001B[0;32m--> 176\u001B[0m     real_table, non_watermark_table, watermark_table, exp_table \u001B[38;5;241m=\u001B[39m \u001B[43mget_tables_by_model_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcommon_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m     result \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    179\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlinear_classification\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogistic_classification\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom_forest_regression\u001B[39m\u001B[38;5;124m'\u001B[39m:[]\n\u001B[1;32m    185\u001B[0m     }\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(trial_num):\n",
      "Cell \u001B[0;32mIn[3], line 75\u001B[0m, in \u001B[0;36mget_tables_by_model_name\u001B[0;34m(model_name, common_size, gamma, delta, other_schemes)\u001B[0m\n\u001B[1;32m     73\u001B[0m synth_no_watermark_path \u001B[38;5;241m=\u001B[39m samples_dir \u001B[38;5;241m+\u001B[39m no_water_mark_file_name\n\u001B[1;32m     74\u001B[0m synth_with_watermark_path \u001B[38;5;241m=\u001B[39m samples_dir \u001B[38;5;241m+\u001B[39m with_water_mark_file_name\n\u001B[0;32m---> 75\u001B[0m exp_path \u001B[38;5;241m=\u001B[39m \u001B[43msamples_dir\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mother_schemes_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     77\u001B[0m real_table \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(real_path)\n\u001B[1;32m     78\u001B[0m non_watermark_table \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(synth_no_watermark_path)\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "models_metadata = [\n",
    "    {'model_name': 'adult', 'target': 'class', 'task_name': 'classification'},\n",
    "    {'model_name': 'california', 'target': 'MedHouseVal', 'task_name': 'regression'},\n",
    "    {'model_name': 'abalone', 'target': 'Rings', 'task_name': 'regression'},\n",
    "    # {'model_name': 'diabetes', 'target': 'Outcome', 'task_name': 'classification'},\n",
    "]\n",
    "\n",
    "gamma_delta_pairs = [(0.25, 5.0), (0.25, 2.0), (0.5, 1.0), (0.5, 2.0)]\n",
    "\n",
    "mle_scores = mle_efficacy(models_metadata, gamma_delta_pairs, trial_num=15)\n",
    "\n",
    "import json\n",
    "# \n",
    "with open('with_exp_except_abalone.json', 'w') as json_file:\n",
    "    json.dump(mle_scores, json_file, indent=4)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T18:39:38.580340Z",
     "start_time": "2024-06-09T18:39:38.524627Z"
    }
   },
   "id": "c08b0640a71f02bc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     Model     γ    δ         Real Non-Watermark    Watermark\n0  abalone  0.25  5.0  0.522±0.028    0.493±0.03  0.346±0.033\n1  abalone  0.25  2.0  0.522±0.028    0.493±0.03  0.398±0.026\n2  abalone  0.50  1.0  0.522±0.028    0.493±0.03  0.472±0.031\n3  abalone  0.50  2.0  0.522±0.028    0.493±0.03  0.463±0.042",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>γ</th>\n      <th>δ</th>\n      <th>Real</th>\n      <th>Non-Watermark</th>\n      <th>Watermark</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abalone</td>\n      <td>0.25</td>\n      <td>5.0</td>\n      <td>0.522±0.028</td>\n      <td>0.493±0.03</td>\n      <td>0.346±0.033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abalone</td>\n      <td>0.25</td>\n      <td>2.0</td>\n      <td>0.522±0.028</td>\n      <td>0.493±0.03</td>\n      <td>0.398±0.026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abalone</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>0.522±0.028</td>\n      <td>0.493±0.03</td>\n      <td>0.472±0.031</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abalone</td>\n      <td>0.50</td>\n      <td>2.0</td>\n      <td>0.522±0.028</td>\n      <td>0.493±0.03</td>\n      <td>0.463±0.042</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "def calculate_confidence_interval(scores):\n",
    "    # Extract R² scores\n",
    "    \n",
    "    # Calculate mean and standard deviation\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores, ddof=1)\n",
    "    \n",
    "    # Calculate the number of samples\n",
    "    n = len(scores)\n",
    "    \n",
    "    # Calculate the standard error of the mean\n",
    "    stderr_mean = std_score / np.sqrt(n)\n",
    "    \n",
    "    # Define the confidence level (e.g., 95%)\n",
    "    confidence_level = 0.95\n",
    "    \n",
    "    # Calculate the critical value\n",
    "    t_critical = t.ppf((1 + confidence_level) / 2, df=n - 1)\n",
    "    \n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = t_critical * stderr_mean\n",
    "    \n",
    "    return mean_score, margin_of_error\n",
    "\n",
    "def get_avg_metrics(all_data):\n",
    "    final_results = []\n",
    "    for data in all_data:\n",
    "        model_name = data['model_name']\n",
    "        gamma = data['gamma']\n",
    "        delta = data['delta']\n",
    "        result = data['result']\n",
    "        tasks= data['tasks']\n",
    "        \n",
    "        real_scores = []\n",
    "        non_watermark_scores = []\n",
    "        watermark_scores = []\n",
    "        # exp_scores = []\n",
    "        \n",
    "        for task in tasks:\n",
    "            for trial_result in result[task]:\n",
    "                metric = 'r2' if 'regression' in task else 'auc' \n",
    "                real_scores.append(trial_result['real'][metric])\n",
    "                non_watermark_scores.append(trial_result['non_watermark'][metric])\n",
    "                watermark_scores.append(trial_result['watermark'][metric])\n",
    "                # exp_scores.append(trial_result['exp'][metric])\n",
    "        \n",
    "        final_results.append({\n",
    "            'model_name': model_name,\n",
    "            'gamma':gamma,\n",
    "            'delta':delta,\n",
    "            'real_score': calculate_confidence_interval(real_scores),\n",
    "            'non_watermark_score': calculate_confidence_interval(non_watermark_scores),\n",
    "            'watermark_score': calculate_confidence_interval(watermark_scores),\n",
    "            # 'exp_score': calculate_confidence_interval(exp_scores)\n",
    "        })\n",
    "             \n",
    "    return final_results\n",
    "\n",
    "def avg_mertrics_to_df(all_data, gamma_delta_pairs):\n",
    "    processed_metrics = get_avg_metrics(all_data)\n",
    "    \n",
    "    model_names = []\n",
    "    gammas = []\n",
    "    deltas = []\n",
    "    real_scores = []\n",
    "    non_watermark_scores = []\n",
    "    watermark_scores = []\n",
    "    # exp_scores = []\n",
    "    \n",
    "    for data in processed_metrics:\n",
    "        model_name = data['model_name']\n",
    "        gamma = data['gamma']\n",
    "        delta = data['delta']\n",
    "        real_score, real_score_margin = data['real_score']\n",
    "        non_watermark_score, non_watermark_score_margin = data['non_watermark_score']\n",
    "        watermark_score, watermark_score_margin = data['watermark_score']\n",
    "        # exp_score, exp_score_margin = data['exp_score']\n",
    "        \n",
    "        model_names.append(model_name)\n",
    "        gammas.append(gamma)\n",
    "        deltas.append(delta)\n",
    "        \n",
    "        real_scores.append(str(round(real_score, 3)) + \"±\" + str(round(real_score_margin, 3)))\n",
    "        non_watermark_scores.append(str(round(non_watermark_score, 3)) + \"±\" + str(round(non_watermark_score_margin, 3)))\n",
    "        watermark_scores.append(str(round(watermark_score, 3)) + \"±\" + str(round(watermark_score_margin, 3)))\n",
    "        # exp_scores.append(str(round(exp_score, 3)) + \"±\" + str(round(exp_score_margin, 3)))\n",
    "\n",
    "    avg_metrics_df = pd.DataFrame({\n",
    "        'Model': model_names,\n",
    "        'γ': gammas,\n",
    "        'δ': deltas,\n",
    "        'Real': real_scores,\n",
    "        # 'Exp': exp_scores,\n",
    "        'Non-Watermark': non_watermark_scores,\n",
    "        'Watermark': watermark_scores,\n",
    "    })\n",
    "    \n",
    "    return avg_metrics_df\n",
    "\n",
    "with open('abalone_without_exp.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    all_data = json.load(file)\n",
    "\n",
    "allauh = avg_mertrics_to_df(all_data, gamma_delta_pairs)\n",
    "# allauh.to_excel(\"output3.xlsx\", index=False)\n",
    "allauh"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-09T18:40:52.214678Z",
     "start_time": "2024-06-09T18:40:52.205544Z"
    }
   },
   "id": "b21153db639d0773",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "894b54d81017528d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
